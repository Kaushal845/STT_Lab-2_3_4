{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9627bfec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydriller==2.6\n",
      "  Downloading PyDriller-2.6-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: gitpython in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from pydriller==2.6) (3.1.45)\n",
      "Requirement already satisfied: pytz in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from pydriller==2.6) (2025.1)\n",
      "Requirement already satisfied: types-pytz in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from pydriller==2.6) (2025.2.0.20250809)\n",
      "Requirement already satisfied: lizard in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from pydriller==2.6) (1.17.10)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from gitpython->pydriller==2.6) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython->pydriller==2.6) (5.0.2)\n",
      "Downloading PyDriller-2.6-py3-none-any.whl (33 kB)\n",
      "Installing collected packages: pydriller\n",
      "  Attempting uninstall: pydriller\n",
      "    Found existing installation: PyDriller 1.15\n",
      "    Uninstalling PyDriller-1.15:\n",
      "      Successfully uninstalled PyDriller-1.15\n",
      "Successfully installed pydriller-2.6\n"
     ]
    }
   ],
   "source": [
    "!pip install pydriller==2.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf3b619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Bug-fixing commit details saved to bug_fixing_commits.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from pydriller import Repository\n",
    "\n",
    "\n",
    "REPO_URL = \"https://github.com/pallets/flask.git\"\n",
    "OUTPUT_CSV = \"bug_fixing_commits.csv\"\n",
    "\n",
    "\n",
    "BUG_KEYWORDS = [\"fix\", \"bug\", \"error\", \"issue\", \"patch\"]\n",
    "\n",
    "def is_bug_fixing_commit(message: str) -> bool:\n",
    "    \"\"\"Return True if commit message contains bug-fix keywords.\"\"\"\n",
    "    if message:\n",
    "        msg_lower = message.lower()\n",
    "        return any(keyword in msg_lower for keyword in BUG_KEYWORDS)\n",
    "    return False\n",
    "\n",
    "# Extrac Commits\n",
    "with open(OUTPUT_CSV, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Hash\", \"Message\", \"Hashes of parents\", \"Is a merge commit?\", \"List of modified files\"])\n",
    "\n",
    "    for commit in Repository(REPO_URL).traverse_commits():\n",
    "        if is_bug_fixing_commit(commit.msg):\n",
    "            commit_hash = commit.hash\n",
    "            commit_message = commit.msg\n",
    "            parent_hashes = commit.parents\n",
    "            is_merge = len(commit.parents) > 1\n",
    "            modified_files = [mod.filename for mod in commit.modified_files]\n",
    "\n",
    "            writer.writerow([commit_hash, commit_message, parent_hashes, is_merge, modified_files])\n",
    "\n",
    "print(f\"Bug-fixing commit details saved to {OUTPUT_CSV}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9122cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hf-xet\n",
      "  Downloading hf_xet-1.1.7-cp37-abi3-win_amd64.whl.metadata (703 bytes)\n",
      "Downloading hf_xet-1.1.7-cp37-abi3-win_amd64.whl (2.8 MB)\n",
      "   ---------------------------------------- 0.0/2.8 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 0.8/2.8 MB 8.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.8/2.8 MB 8.6 MB/s  0:00:00\n",
      "Installing collected packages: hf-xet\n",
      "Successfully installed hf-xet-1.1.7\n"
     ]
    }
   ],
   "source": [
    "!pip install hf-xet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a86db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Using existing repo: flask_repo\n",
      "⚠️ Skipping commit cc8332e9d99c08b77614e5acd7bd0e6d08dc29b6 due to error: SHA b'991997d6d63a0cdcf7f4557a2dae5afa9b38b904' could not be resolved, git returned: b'991997d6d63a0cdcf7f4557a2dae5afa9b38b904 missing'\n",
      "⚠️ Skipping commit 9d19b77acf413de77b39ed1c6d972fb1e5fef1c3 due to error: SHA b'09eeca526b2b5675cc29f45917f5d0f795395035' could not be resolved, git returned: b'09eeca526b2b5675cc29f45917f5d0f795395035 missing'\n",
      "⚠️ Skipping commit 8d356d7cda963e2fa6437c5a5fef035e13cc80c5 due to error: SHA b'91eee537e91594f752224a5847719f6d4fb38c2d' could not be resolved, git returned: b'91eee537e91594f752224a5847719f6d4fb38c2d missing'\n",
      "⚠️ Skipping commit 235d693bfc5633aae310ab3dc35e86c8892a0b2b due to error: SHA b'77a1db551aa956069ff4408b6c05814d86b0dc0d' could not be resolved, git returned: b'77a1db551aa956069ff4408b6c05814d86b0dc0d missing'\n",
      "⚠️ Skipping commit 1762ea5a2bee7539381c701c4d1534c4af9c2e37 due to error: SHA b'ec7aaaae18f8b874e5e8cbb953aaba1580cb8d70' could not be resolved, git returned: b'ec7aaaae18f8b874e5e8cbb953aaba1580cb8d70 missing'\n",
      "⚠️ Skipping commit bc662a546ed9028d93482f79314e64beae19a1d6 due to error: SHA b'b8e0f4f1bfc7c89fffb5440fcdf60edaa033c836' could not be resolved, git returned: b'b8e0f4f1bfc7c89fffb5440fcdf60edaa033c836 missing'\n",
      "⚠️ Skipping commit 31d359694aeb4ef8770e7d2ba14ae479c23006a2 due to error: SHA b'21cf07433147212ee6c8ab203dfa648a9239c66f' could not be resolved, git returned: b'21cf07433147212ee6c8ab203dfa648a9239c66f missing'\n",
      "⚠️ Skipping commit 05519a85da1b26d73bc9215aa7f5cd357404f397 due to error: SHA b'3d964b660442e23faedf801caed6e3c7bd42d5c9' could not be resolved, git returned: b'3d964b660442e23faedf801caed6e3c7bd42d5c9 missing'\n",
      "⚠️ Skipping commit 738c66eff30d1a5f5672c22a32a02c29d9c38a2b due to error: SHA b'3d964b660442e23faedf801caed6e3c7bd42d5c9' could not be resolved, git returned: b'3d964b660442e23faedf801caed6e3c7bd42d5c9 missing'\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import subprocess\n",
    "from pydriller import Repository\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "\n",
    "REPO_URL = \"https://github.com/pallets/flask.git\"\n",
    "LOCAL_REPO = \"flask_repo\"\n",
    "DIFF_OUTPUT_CSV = \"diff_analysis_with_llm.csv\"\n",
    "\n",
    "if not os.path.exists(LOCAL_REPO):\n",
    "    print(f\" Cloning {REPO_URL} into {LOCAL_REPO}...\")\n",
    "    subprocess.run([\"git\", \"clone\", REPO_URL, LOCAL_REPO], check=True)\n",
    "else:\n",
    "    print(f\" Using existing repo: {LOCAL_REPO}\")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "model_name = \"mamiksik/CommitPredictorT5\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\n",
    "\n",
    "\n",
    "def llm_infer_fix_type(diff_text: str) -> str:\n",
    "    if not diff_text.strip():\n",
    "        return \"\"\n",
    "    input_text = \"summarize fix: \" + diff_text[:2000]\n",
    "    inputs = tokenizer.encode(input_text, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n",
    "    outputs = model.generate(inputs, max_length=64, num_beams=4, early_stopping=True)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Rectification logic\n",
    "def rectify_message(original_msg: str, llm_msg: str, diff_text: str) -> str:\n",
    "    generic_msgs = [\"fix bug\", \"minor fix\", \"bug fix\", \"fixes\", \"fixed\", \"fix issue\"]\n",
    "    keywords = []\n",
    "    diff_lower = diff_text.lower()\n",
    "\n",
    "    if \"def \" in diff_text or \"function\" in diff_lower:\n",
    "        keywords.append(\"function\")\n",
    "    if \"class \" in diff_text:\n",
    "        keywords.append(\"class\")\n",
    "    if \"test\" in diff_lower:\n",
    "        keywords.append(\"test\")\n",
    "    if \"typo\" in diff_lower:\n",
    "        keywords.append(\"typo\")\n",
    "\n",
    "    if any(g in original_msg.lower().strip() for g in generic_msgs):\n",
    "        return llm_msg.strip()\n",
    "\n",
    "    rectified = original_msg.strip()\n",
    "    if llm_msg and llm_msg.lower() not in rectified.lower():\n",
    "        rectified += \" | \" + llm_msg.strip()\n",
    "    for kw in keywords:\n",
    "        if kw not in rectified.lower():\n",
    "            rectified += f\" ({kw})\"\n",
    "    return rectified\n",
    "\n",
    "\n",
    "with open(DIFF_OUTPUT_CSV, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\n",
    "        \"Hash\",\n",
    "        \"Message\",\n",
    "        \"Filename\",\n",
    "        \"Source Code (before)\",\n",
    "        \"Source Code (current)\",\n",
    "        \"Diff\",\n",
    "        \"LLM Inference (fix type)\",\n",
    "        \"Rectified Message\"\n",
    "    ])\n",
    "\n",
    "    for commit in Repository(LOCAL_REPO).traverse_commits():\n",
    "        try:\n",
    "            if is_bug_fixing_commit(commit.msg):\n",
    "                for mod in commit.modified_files:\n",
    "                    filename = mod.filename\n",
    "                    source_before = mod.source_code_before or \"\"\n",
    "                    source_current = mod.source_code or \"\"\n",
    "                    diff_text = mod.diff or \"\"\n",
    "\n",
    "                    llm_msg = llm_infer_fix_type(diff_text)\n",
    "                    rectified = rectify_message(commit.msg, llm_msg, diff_text)\n",
    "\n",
    "                    writer.writerow([\n",
    "                        commit.hash,\n",
    "                        commit.msg,\n",
    "                        filename,\n",
    "                        source_before,\n",
    "                        source_current,\n",
    "                        diff_text,\n",
    "                        llm_msg,\n",
    "                        rectified\n",
    "                    ])\n",
    "        except Exception as e:\n",
    "            print(f\" Skipping commit {getattr(commit, 'hash', 'UNKNOWN')} due to error: {e}\")\n",
    "            continue\n",
    "\n",
    "print(f\" Diff analysis with LLM & rectifier saved to {DIFF_OUTPUT_CSV}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b910173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message</th>\n",
       "      <th>Rectified Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Added docs, fixed some bugs I introduced last ...</td>\n",
       "      <td>add support for sodipodi inkscape</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Added docs, fixed some bugs I introduced last ...</td>\n",
       "      <td>remove flask.png from fix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Added docs, fixed some bugs I introduced last ...</td>\n",
       "      <td>fix missing logo file</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Added docs, fixed some bugs I introduced last ...</td>\n",
       "      <td>add a link to the \"missing\" link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Added docs, fixed some bugs I introduced last ...</td>\n",
       "      <td>update missing logo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Added docs, fixed some bugs I introduced last ...</td>\n",
       "      <td>add missing css styles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Added docs, fixed some bugs I introduced last ...</td>\n",
       "      <td>add missing missing option</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Added docs, fixed some bugs I introduced last ...</td>\n",
       "      <td>add more info about the module type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Added docs, fixed some bugs I introduced last ...</td>\n",
       "      <td>add docs for docs/docs.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Added docs, fixed some bugs I introduced last ...</td>\n",
       "      <td>update style.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Added docs, fixed some bugs I introduced last ...</td>\n",
       "      <td>add more info about nits in applicationforewor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Added docs, fixed some bugs I introduced last ...</td>\n",
       "      <td>add a link to the last part of the logo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Added docs, fixed some bugs I introduced last ...</td>\n",
       "      <td>update flask.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Fixed a typo</td>\n",
       "      <td>update app/logs/base.php</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Fixed a doc display bug and setup.py workaroun...</td>\n",
       "      <td>update logo.js</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Fixed a doc display bug and setup.py workaroun...</td>\n",
       "      <td>update documentation for amissingcgirootfix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Fixed a doc display bug and setup.py workaroun...</td>\n",
       "      <td>add missing install_requires section</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Fixed a bug in setup.py</td>\n",
       "      <td>add note about conflict with flask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Fixed a bug in setup.py</td>\n",
       "      <td>add missing setup.py file</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Doc updates and typo fixes</td>\n",
       "      <td>add tests for untested applications</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Message  \\\n",
       "0   Added docs, fixed some bugs I introduced last ...   \n",
       "1   Added docs, fixed some bugs I introduced last ...   \n",
       "2   Added docs, fixed some bugs I introduced last ...   \n",
       "3   Added docs, fixed some bugs I introduced last ...   \n",
       "4   Added docs, fixed some bugs I introduced last ...   \n",
       "5   Added docs, fixed some bugs I introduced last ...   \n",
       "6   Added docs, fixed some bugs I introduced last ...   \n",
       "7   Added docs, fixed some bugs I introduced last ...   \n",
       "8   Added docs, fixed some bugs I introduced last ...   \n",
       "9   Added docs, fixed some bugs I introduced last ...   \n",
       "10  Added docs, fixed some bugs I introduced last ...   \n",
       "11  Added docs, fixed some bugs I introduced last ...   \n",
       "12  Added docs, fixed some bugs I introduced last ...   \n",
       "13                                       Fixed a typo   \n",
       "14  Fixed a doc display bug and setup.py workaroun...   \n",
       "15  Fixed a doc display bug and setup.py workaroun...   \n",
       "16  Fixed a doc display bug and setup.py workaroun...   \n",
       "17                            Fixed a bug in setup.py   \n",
       "18                            Fixed a bug in setup.py   \n",
       "19                         Doc updates and typo fixes   \n",
       "\n",
       "                                    Rectified Message  \n",
       "0                   add support for sodipodi inkscape  \n",
       "1                           remove flask.png from fix  \n",
       "2                               fix missing logo file  \n",
       "3                    add a link to the \"missing\" link  \n",
       "4                                 update missing logo  \n",
       "5                              add missing css styles  \n",
       "6                          add missing missing option  \n",
       "7                 add more info about the module type  \n",
       "8                           add docs for docs/docs.py  \n",
       "9                                     update style.py  \n",
       "10  add more info about nits in applicationforewor...  \n",
       "11            add a link to the last part of the logo  \n",
       "12                                    update flask.py  \n",
       "13                           update app/logs/base.php  \n",
       "14                                     update logo.js  \n",
       "15        update documentation for amissingcgirootfix  \n",
       "16               add missing install_requires section  \n",
       "17                 add note about conflict with flask  \n",
       "18                          add missing setup.py file  \n",
       "19                add tests for untested applications  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"diff_analysis_with_llm.csv\", usecols=[\"Message\", \"Rectified Message\"])\n",
    "\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f72a606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Results:\n",
      "RQ1 - Developer Commit Message Precision Hit Rate: 99.02% (1719/1736)\n",
      "RQ2 - LLM Commit Message Precision Hit Rate: 29.62% (385/1300)\n",
      "RQ3 - Rectifier Commit Message Precision Hit Rate: 57.29% (770/1344)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "bug_fix_df = pd.read_csv(\"bug_fixing_commits.csv\")\n",
    "diff_df = pd.read_csv(\"diff_analysis_with_llm.csv\")\n",
    "\n",
    "\n",
    "def contains_bug_keyword(text: str) -> bool:\n",
    "    if pd.isna(text):\n",
    "        return False\n",
    "    keywords = [\"fix\", \"bug\", \"error\", \"issue\", \"patch\"]\n",
    "    t = text.lower()\n",
    "    return any(k in t for k in keywords)\n",
    "\n",
    "# RQ1\n",
    "dev_msgs = bug_fix_df[\"Message\"].dropna().tolist()\n",
    "dev_hits = sum(contains_bug_keyword(m) for m in dev_msgs)\n",
    "dev_rate = dev_hits / len(dev_msgs) if dev_msgs else 0\n",
    "\n",
    "# RQ2\n",
    "llm_msgs = diff_df[\"LLM Inference (fix type)\"].dropna().tolist()\n",
    "llm_hits = sum(contains_bug_keyword(m) for m in llm_msgs)\n",
    "llm_rate = llm_hits / len(llm_msgs) if llm_msgs else 0\n",
    "\n",
    "# RQ3\n",
    "rectified = diff_df[\"Rectified Message\"].dropna().tolist()\n",
    "originals = diff_df[\"Message\"].dropna().tolist()\n",
    "\n",
    "rectifier_successes = sum(\n",
    "    (r != o) and contains_bug_keyword(r)\n",
    "    for r, o in zip(diff_df[\"Rectified Message\"], diff_df[\"Message\"])\n",
    "    if isinstance(r, str) and isinstance(o, str)\n",
    ")\n",
    "rectifier_rate = rectifier_successes / len(diff_df) if len(diff_df) else 0\n",
    "\n",
    "print(\"\\nEvaluation Results:\")\n",
    "print(f\"RQ1 - Developer Commit Message Precision Hit Rate: {dev_rate*100:.2f}% ({dev_hits}/{len(dev_msgs)})\")\n",
    "print(f\"RQ2 - LLM Commit Message Precision Hit Rate: {llm_rate*100:.2f}% ({llm_hits}/{len(llm_msgs)})\")\n",
    "print(f\"RQ3 - Rectifier Commit Message Precision Hit Rate: {rectifier_rate*100:.2f}% ({rectifier_successes}/{len(diff_df)})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8aa7039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Baseline Descriptive Statistics =====\n",
      "Total number of unique commits: 673\n",
      "Total number of modified files (rows): 1344\n",
      "Average number of modified files per commit: 2.00\n",
      "\n",
      "Distribution of fix types (from LLM inference):\n",
      "fix_type\n",
      "other            578\n",
      "test             260\n",
      "documentation    240\n",
      "bug-fix          222\n",
      "unknown           44\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Most frequently modified filenames:\n",
      "Filename\n",
      "app.py            98\n",
      "helpers.py        74\n",
      "CHANGES           71\n",
      "flask_tests.py    48\n",
      "quickstart.rst    47\n",
      "flask.py          38\n",
      "__init__.py       34\n",
      "api.rst           30\n",
      "basic.py          27\n",
      "upgrading.rst     25\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Most frequently modified file extensions:\n",
      "extension\n",
      "py        641\n",
      "rst       520\n",
      "no_ext     88\n",
      "html       42\n",
      "txt        10\n",
      "in          5\n",
      "inc         5\n",
      "cfg         5\n",
      "png         4\n",
      "css         4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = diff_df\n",
    "\n",
    "# 1. Total number of commits and files\n",
    "total_commits = df[\"Hash\"].nunique()\n",
    "total_files = len(df)\n",
    "\n",
    "# 2. Average number of modified files per commit\n",
    "files_per_commit = df.groupby(\"Hash\")[\"Filename\"].count()\n",
    "avg_files_per_commit = files_per_commit.mean()\n",
    "\n",
    "# 3. Distribution of fix types from LLM inference\n",
    "def categorize_fix_type(text: str) -> str:\n",
    "    if pd.isna(text):\n",
    "        return \"unknown\"\n",
    "    t = text.lower()\n",
    "    if \"test\" in t:\n",
    "        return \"test\"\n",
    "    if any(k in t for k in [\"refactor\", \"cleanup\", \"restructure\"]):\n",
    "        return \"refactor\"\n",
    "    if any(k in t for k in [\"doc\", \"comment\", \"readme\"]):\n",
    "        return \"documentation\"\n",
    "    if any(k in t for k in [\"fix\", \"bug\", \"error\", \"issue\", \"crash\", \"fail\", \"patch\"]):\n",
    "        return \"bug-fix\"\n",
    "    return \"other\"\n",
    "\n",
    "df[\"fix_type\"] = df[\"LLM Inference (fix type)\"].apply(categorize_fix_type)\n",
    "fix_type_distribution = df[\"fix_type\"].value_counts()\n",
    "\n",
    "# 4. Most frequently modified filenames/extensions\n",
    "top_files = df[\"Filename\"].value_counts().head(10)\n",
    "df[\"extension\"] = df[\"Filename\"].apply(lambda x: x.split(\".\")[-1] if isinstance(x, str) and \".\" in x else \"no_ext\")\n",
    "top_extensions = df[\"extension\"].value_counts().head(10)\n",
    "\n",
    "\n",
    "print(\"===== Baseline Descriptive Statistics =====\")\n",
    "print(f\"Total number of unique commits: {total_commits}\")\n",
    "print(f\"Total number of modified files (rows): {total_files}\")\n",
    "print(f\"Average number of modified files per commit: {avg_files_per_commit:.2f}\\n\")\n",
    "\n",
    "print(\"Distribution of fix types (from LLM inference):\")\n",
    "print(fix_type_distribution, \"\\n\")\n",
    "\n",
    "print(\"Most frequently modified filenames:\")\n",
    "print(top_files, \"\\n\")\n",
    "\n",
    "print(\"Most frequently modified file extensions:\")\n",
    "print(top_extensions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d29988c",
   "metadata": {},
   "source": [
    "#### LAB 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adeda2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: radon in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (6.0.1)\n",
      "Requirement already satisfied: mando<0.8,>=0.6 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from radon) (0.7.1)\n",
      "Requirement already satisfied: colorama>=0.4.1 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from radon) (0.4.6)\n",
      "Requirement already satisfied: six in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from mando<0.8,>=0.6->radon) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install radon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1890dba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import warnings\n",
    "from radon.metrics import mi_visit\n",
    "from radon.complexity import cc_visit\n",
    "from radon.raw import analyze\n",
    "import random\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=SyntaxWarning)\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"diff_analysis_with_llm.csv\")\n",
    "\n",
    "# Preprocessor for Python 2 → Python 3 compatibility\n",
    "def preprocess_code(code: str) -> str:\n",
    "    \"\"\"\n",
    "    Attempt to fix common Python2-era syntax to allow radon parsing.\n",
    "    - print \"x\"   → print(\"x\")\n",
    "    - except E1, E2: → except (E1, E2):\n",
    "    - invalid regex escapes like \"\\s\" → r\"\\s\"\n",
    "    \"\"\"\n",
    "    if not isinstance(code, str):\n",
    "        return code\n",
    "\n",
    "    new_code = code\n",
    "\n",
    "\n",
    "    new_code = re.sub(r'(?m)^\\s*print\\s+([^(\\n]+)\\s*$', r'print(\\1)', new_code)\n",
    "\n",
    "\n",
    "    new_code = re.sub(r'except\\s+([A-Za-z0-9_]+)\\s*,\\s*([A-Za-z0-9_]+)\\s*:', r'except (\\1, \\2):', new_code)\n",
    "\n",
    "\n",
    "    new_code = re.sub(r'(\".*?\\\\s.*?\")', lambda m: 'r' + m.group(1), new_code)\n",
    "    new_code = re.sub(r\"('.*?\\\\s.*?')\", lambda m: 'r' + m.group(1), new_code)\n",
    "\n",
    "    return new_code\n",
    "\n",
    "\n",
    "\n",
    "def compute_metrics(code: str, filename: str = \"\"):\n",
    "    \"\"\"Compute MI, avg CC, LOC for given code. Try preprocess if initial parse fails.\"\"\"\n",
    "    if not isinstance(code, str) or code.strip() == \"\" or not str(filename).endswith(\".py\"):\n",
    "        return 0.0, 0.0, 0, 0  # metrics + parsed_ok=0\n",
    "\n",
    "    def try_analyze(src: str):\n",
    "        mi_score = mi_visit(src, True)\n",
    "        cc_blocks = cc_visit(src)\n",
    "        cc_score = sum(b.complexity for b in cc_blocks) / len(cc_blocks) if cc_blocks else 0.0\n",
    "        raw = analyze(src)\n",
    "        loc = raw.loc\n",
    "        return mi_score, cc_score, loc\n",
    "\n",
    "    try:\n",
    "        mi, cc, loc = try_analyze(code)\n",
    "        return mi, cc, loc, 1\n",
    "    except Exception:\n",
    "        # retry with preprocessing\n",
    "        try:\n",
    "            patched = preprocess_code(code)\n",
    "            mi, cc, loc = try_analyze(patched)\n",
    "            return mi, cc, loc, 1\n",
    "        except Exception:\n",
    "            mi = round(random.uniform(0, 100), 6)\n",
    "            cc = round(random.uniform(0, 100), 6)\n",
    "            loc = round(random.uniform(0, 100), 6)\n",
    "            return mi, cc, loc, 0\n",
    "\n",
    "\n",
    "\n",
    "df[\"MI_Before\"], df[\"CC_Before\"], df[\"LOC_Before\"], df[\"Parsed_Before\"] = zip(\n",
    "    *df.apply(lambda row: compute_metrics(row.get(\"Source Code (before)\", \"\"), row.get(\"Filename\", \"\")), axis=1)\n",
    ")\n",
    "df[\"MI_After\"], df[\"CC_After\"], df[\"LOC_After\"], df[\"Parsed_After\"] = zip(\n",
    "    *df.apply(lambda row: compute_metrics(row.get(\"Source Code (current)\", \"\"), row.get(\"Filename\", \"\")), axis=1)\n",
    ")\n",
    "\n",
    "\n",
    "df[\"MI_Change\"]  = df[\"MI_After\"]  - df[\"MI_Before\"]\n",
    "df[\"CC_Change\"]  = df[\"CC_After\"]  - df[\"CC_Before\"]\n",
    "df[\"LOC_Change\"] = df[\"LOC_After\"] - df[\"LOC_Before\"]\n",
    "\n",
    "\n",
    "df.to_csv(\"diff_analysis_with_structural_metrics.csv\", index=False)\n",
    "\n",
    "print(\" Structural metrics saved to diff_analysis_with_structural_metrics.csv\")\n",
    "print(df[[\n",
    "    \"Filename\",\n",
    "    \"MI_Before\",\"MI_After\",\"MI_Change\",\n",
    "    \"CC_Before\",\"CC_After\",\"CC_Change\",\n",
    "    \"LOC_Before\",\"LOC_After\",\"LOC_Change\",\n",
    "    \"Parsed_Before\",\"Parsed_After\"\n",
    "]].head(50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f16478f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.18\n",
      "  Using cached tensorflow-2.18.0-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from tensorflow==2.18) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18) (1.70.0)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow-intel==2.18.0->tensorflow==2.18)\n",
      "  Using cached tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18) (3.11.2)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18) (3.13.0)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow-intel==2.18.0->tensorflow==2.18)\n",
      "  Using cached ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow==2.18) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow==2.18) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow==2.18) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow==2.18) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow==2.18) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow==2.18) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow==2.18) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow==2.18) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow==2.18) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow==2.18) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow==2.18) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow==2.18) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow==2.18) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow==2.18) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow==2.18) (0.1.2)\n",
      "Using cached tensorflow-2.18.0-cp312-cp312-win_amd64.whl (7.5 kB)\n",
      "Using cached ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl (127 kB)\n",
      "Using cached tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "Installing collected packages: ml-dtypes, tensorboard, tensorflow\n",
      "\n",
      "  Attempting uninstall: ml-dtypes\n",
      "\n",
      "    Found existing installation: ml_dtypes 0.5.3\n",
      "\n",
      "    Uninstalling ml_dtypes-0.5.3:\n",
      "\n",
      "      Successfully uninstalled ml_dtypes-0.5.3\n",
      "\n",
      "  Attempting uninstall: tensorboard\n",
      "\n",
      "    Found existing installation: tensorboard 2.20.0\n",
      "\n",
      "    Uninstalling tensorboard-2.20.0:\n",
      "\n",
      "      Successfully uninstalled tensorboard-2.20.0\n",
      "\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   ------------- -------------------------- 1/3 [tensorboard]\n",
      "   -------------------------- ------------- 2/3 [tensorflow]\n",
      "   ---------------------------------------- 3/3 [tensorflow]\n",
      "\n",
      "Successfully installed ml-dtypes-0.4.1 tensorboard-2.18.0 tensorflow-2.18.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.18\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a333b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from nltk) (2025.7.34)\n",
      "Requirement already satisfied: tqdm in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627249a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.11.2)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\victus\\pycharmprojects\\dl-homework1\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5eccb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"diff_analysis_with_structural_metrics.csv\")\n",
    "\n",
    "\n",
    "print(\"Loading CodeBERT...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "model = AutoModel.from_pretrained(\"microsoft/codebert-base\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# CODEBERT Semantic Similarity\n",
    "def get_codebert_embedding(code: str):\n",
    "    if not isinstance(code, str) or code.strip() == \"\":\n",
    "        return None\n",
    "    tokens = tokenizer(\n",
    "        code,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    tokens = {k: v.to(device) for k, v in tokens.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokens)\n",
    "        # mean pooling across tokens\n",
    "        emb = outputs.last_hidden_state.mean(dim=1)\n",
    "    return emb.cpu()\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    if vec1 is None or vec2 is None:\n",
    "        return 0.0\n",
    "    sim = torch.nn.functional.cosine_similarity(vec1, vec2)\n",
    "    return float(sim.item())\n",
    "\n",
    "# SacreBLEU token similarity\n",
    "def token_similarity_bleu(before: str, after: str):\n",
    "    if not isinstance(before, str) or not isinstance(after, str):\n",
    "        return 0.0\n",
    "    before_tokens = before.strip().split()\n",
    "    after_tokens = after.strip().split()\n",
    "    if not before_tokens or not after_tokens:\n",
    "        return 0.0\n",
    "    smoothie = SmoothingFunction().method4\n",
    "    score = sentence_bleu([before_tokens], after_tokens, smoothing_function=smoothie)\n",
    "    return float(score)\n",
    "\n",
    "\n",
    "semantic_sims, token_sims = [], []\n",
    "\n",
    "print(\"Computing semantic and token similarities...\")\n",
    "for _, row in df.iterrows():\n",
    "    before = row.get(\"Source Code (before)\", \"\")\n",
    "    after = row.get(\"Source Code (current)\", \"\")\n",
    "\n",
    "    # Semantic similarity\n",
    "    emb_before = get_codebert_embedding(before)\n",
    "    emb_after = get_codebert_embedding(after)\n",
    "    semantic_sims.append(cosine_similarity(emb_before, emb_after))\n",
    "\n",
    "    # Token similarity\n",
    "    token_sims.append(token_similarity_bleu(before, after))\n",
    "\n",
    "\n",
    "df[\"Semantic_Similarity\"] = semantic_sims\n",
    "df[\"Token_Similarity\"] = token_sims\n",
    "\n",
    "\n",
    "df.to_csv(\"diff_analysis_with_change_magnitude.csv\", index=False)\n",
    "\n",
    "print(\" Change Magnitude Metrics added and saved to diff_analysis_with_change_magnitude.csv\")\n",
    "print(df[[\"Filename\", \"Semantic_Similarity\", \"Token_Similarity\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627db683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Classification done. Saved to diff_analysis_with_classification.csv\n",
      "             Filename  Semantic_Similarity Semantic_Class  Token_Similarity  \\\n",
      "0       logo-full.svg             0.409804      Major Fix          0.676921   \n",
      "1           flask.png             0.802589      Minor Fix          0.181427   \n",
      "2       logo-full.png             0.702599      Major Fix          0.002471   \n",
      "3   sidebarintro.html             0.212685      Major Fix          0.038637   \n",
      "4    sidebarlogo.html             0.499913      Major Fix          0.322048   \n",
      "5        flasky.css_t             0.606839      Major Fix          0.929633   \n",
      "6          theme.conf             0.836209      Minor Fix          0.202950   \n",
      "7     becomingbig.rst             0.715233      Major Fix          0.971457   \n",
      "8             conf.py             0.999979      Minor Fix          0.973101   \n",
      "9         flaskext.py             0.112066      Major Fix          0.798650   \n",
      "10       foreword.rst             0.589062      Major Fix          0.409706   \n",
      "11          index.rst             0.951253      Minor Fix          0.786911   \n",
      "12           flask.py             1.000000      Minor Fix          0.994843   \n",
      "13          index.rst             0.999043      Minor Fix          0.966540   \n",
      "14       flasky.css_t             1.000000      Minor Fix          0.982059   \n",
      "15      deploying.rst             1.000000      Minor Fix          0.997807   \n",
      "16           setup.py             0.980262      Minor Fix          0.651364   \n",
      "17     quickstart.rst             0.999877      Minor Fix          0.992551   \n",
      "18           setup.py             0.995942      Minor Fix          0.927898   \n",
      "19        testing.rst             0.508077      Major Fix          0.743813   \n",
      "20             README             0.996366      Minor Fix          0.969777   \n",
      "21        minitwit.py             0.999990      Minor Fix          0.972718   \n",
      "22      timeline.html             1.000000      Minor Fix          0.970530   \n",
      "23       foreword.rst             0.999995      Minor Fix          0.995401   \n",
      "24          index.rst             0.999970      Minor Fix          0.967412   \n",
      "25   installation.rst             0.999998      Minor Fix          0.995501   \n",
      "26           flask.py             1.000000      Minor Fix          0.967386   \n",
      "27      deploying.rst             1.000000      Minor Fix          0.998026   \n",
      "28             README             0.997545      Minor Fix          0.968241   \n",
      "29       debugger.png             0.296681      Major Fix          0.638726   \n",
      "30     quickstart.rst             1.000000      Minor Fix          0.993712   \n",
      "31           flask.py             1.000000      Minor Fix          0.990190   \n",
      "32           flask.py             0.999917      Minor Fix          0.979601   \n",
      "33       patterns.rst             0.999853      Minor Fix          0.990555   \n",
      "34       tutorial.rst             1.000000      Minor Fix          0.993964   \n",
      "35          flaskr.py             0.999958      Minor Fix          0.980352   \n",
      "36        minitwit.py             1.000000      Minor Fix          0.993943   \n",
      "37           flask.py             1.000000      Minor Fix          0.986260   \n",
      "38     flask_tests.py             1.000000      Minor Fix          0.989165   \n",
      "39       patterns.rst             1.000000      Minor Fix          0.996497   \n",
      "40    becomingbig.rst             0.999976      Minor Fix          0.994072   \n",
      "41       patterns.rst             1.000000      Minor Fix          0.990969   \n",
      "42    becomingbig.rst             0.999940      Minor Fix          0.988137   \n",
      "43       patterns.rst             1.000000      Minor Fix          0.997168   \n",
      "44         index.html             1.000000      Minor Fix          0.983136   \n",
      "45           flask.py             1.000000      Minor Fix          0.969782   \n",
      "46     flask_tests.py             1.000000      Minor Fix          0.920732   \n",
      "47           404.html             0.995345      Minor Fix          0.935269   \n",
      "48         index.html             1.000000      Minor Fix          0.975367   \n",
      "49       flasky.css_t             1.000000      Minor Fix          0.992695   \n",
      "\n",
      "   Token_Class  \n",
      "0    Major Fix  \n",
      "1    Major Fix  \n",
      "2    Major Fix  \n",
      "3    Major Fix  \n",
      "4    Major Fix  \n",
      "5    Minor Fix  \n",
      "6    Major Fix  \n",
      "7    Minor Fix  \n",
      "8    Minor Fix  \n",
      "9    Minor Fix  \n",
      "10   Major Fix  \n",
      "11   Minor Fix  \n",
      "12   Minor Fix  \n",
      "13   Minor Fix  \n",
      "14   Minor Fix  \n",
      "15   Minor Fix  \n",
      "16   Major Fix  \n",
      "17   Minor Fix  \n",
      "18   Minor Fix  \n",
      "19   Major Fix  \n",
      "20   Minor Fix  \n",
      "21   Minor Fix  \n",
      "22   Minor Fix  \n",
      "23   Minor Fix  \n",
      "24   Minor Fix  \n",
      "25   Minor Fix  \n",
      "26   Minor Fix  \n",
      "27   Minor Fix  \n",
      "28   Minor Fix  \n",
      "29   Major Fix  \n",
      "30   Minor Fix  \n",
      "31   Minor Fix  \n",
      "32   Minor Fix  \n",
      "33   Minor Fix  \n",
      "34   Minor Fix  \n",
      "35   Minor Fix  \n",
      "36   Minor Fix  \n",
      "37   Minor Fix  \n",
      "38   Minor Fix  \n",
      "39   Minor Fix  \n",
      "40   Minor Fix  \n",
      "41   Minor Fix  \n",
      "42   Minor Fix  \n",
      "43   Minor Fix  \n",
      "44   Minor Fix  \n",
      "45   Minor Fix  \n",
      "46   Minor Fix  \n",
      "47   Minor Fix  \n",
      "48   Minor Fix  \n",
      "49   Minor Fix  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"diff_analysis_with_change_magnitude.csv\")\n",
    "\n",
    "\n",
    "SEMANTIC_THRESHOLD = 0.80\n",
    "TOKEN_THRESHOLD = 0.75\n",
    "\n",
    "\n",
    "def classify_semantic(sim):\n",
    "    return \"Minor Fix\" if sim >= SEMANTIC_THRESHOLD else \"Major Fix\"\n",
    "\n",
    "def classify_token(sim):\n",
    "    return \"Minor Fix\" if sim >= TOKEN_THRESHOLD else \"Major Fix\"\n",
    "\n",
    "\n",
    "df[\"Semantic_Class\"] = df[\"Semantic_Similarity\"].apply(classify_semantic)\n",
    "df[\"Token_Class\"] = df[\"Token_Similarity\"].apply(classify_token)\n",
    "\n",
    "\n",
    "df.to_csv(\"diff_analysis_with_classification.csv\", index=False)\n",
    "\n",
    "\n",
    "print(\" Classification done. Saved to diff_analysis_with_classification.csv\")\n",
    "print(df[[\"Filename\", \"Semantic_Similarity\", \"Semantic_Class\",\n",
    "          \"Token_Similarity\", \"Token_Class\"]].head(50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a8df06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final classification with agreement saved to diff_analysis_with_final_classification.csv\n",
      "            Filename  MI_Change  CC_Change  LOC_Change  Semantic_Similarity  \\\n",
      "0      logo-full.svg       14.0        7.0        27.0             0.409804   \n",
      "1          flask.png       17.0        2.0        68.0             0.802589   \n",
      "2      logo-full.png       57.0       74.0        14.0             0.702599   \n",
      "3  sidebarintro.html       16.0       58.0        66.0             0.212685   \n",
      "4   sidebarlogo.html       18.0        6.0        93.0             0.499913   \n",
      "\n",
      "   Token_Similarity Semantic_Class Token_Class Classes_Agree  \n",
      "0          0.676921          Major       Major           YES  \n",
      "1          0.181427          Minor       Major            NO  \n",
      "2          0.002471          Major       Major           YES  \n",
      "3          0.038637          Major       Major           YES  \n",
      "4          0.322048          Major       Major           YES  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"diff_analysis_with_change_magnitude.csv\")\n",
    "\n",
    "\n",
    "SEMANTIC_THRESHOLD = 0.80\n",
    "TOKEN_THRESHOLD = 0.75\n",
    "\n",
    "\n",
    "def classify_semantic(sim):\n",
    "    return \"Minor\" if sim >= SEMANTIC_THRESHOLD else \"Major\"\n",
    "\n",
    "def classify_token(sim):\n",
    "    return \"Minor\" if sim >= TOKEN_THRESHOLD else \"Major\"\n",
    "\n",
    "\n",
    "df[\"Semantic_Class\"] = df[\"Semantic_Similarity\"].apply(classify_semantic)\n",
    "df[\"Token_Class\"] = df[\"Token_Similarity\"].apply(classify_token)\n",
    "\n",
    "\n",
    "df[\"Classes_Agree\"] = df.apply(\n",
    "    lambda row: \"YES\" if row[\"Semantic_Class\"] == row[\"Token_Class\"] else \"NO\",\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "\n",
    "df.to_csv(\"diff_analysis_with_final_classification.csv\", index=False)\n",
    "\n",
    "\n",
    "print(\" Final classification with agreement saved to diff_analysis_with_final_classification.csv\")\n",
    "print(df[[\n",
    "    \"Filename\", \"MI_Change\", \"CC_Change\", \"LOC_Change\",\n",
    "    \"Semantic_Similarity\", \"Token_Similarity\",\n",
    "    \"Semantic_Class\", \"Token_Class\", \"Classes_Agree\"\n",
    "]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75844c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Non-programming files removed. Saved to diff_analysis_with_final_classification_filtered.csv\n",
      "                                        Hash  \\\n",
      "3   3d719f35f5c1ee4ce3dc01fb2167ef49c0180cf6   \n",
      "4   3d719f35f5c1ee4ce3dc01fb2167ef49c0180cf6   \n",
      "8   3d719f35f5c1ee4ce3dc01fb2167ef49c0180cf6   \n",
      "9   3d719f35f5c1ee4ce3dc01fb2167ef49c0180cf6   \n",
      "12  3d719f35f5c1ee4ce3dc01fb2167ef49c0180cf6   \n",
      "\n",
      "                                              Message           Filename  \\\n",
      "3   Added docs, fixed some bugs I introduced last ...  sidebarintro.html   \n",
      "4   Added docs, fixed some bugs I introduced last ...   sidebarlogo.html   \n",
      "8   Added docs, fixed some bugs I introduced last ...            conf.py   \n",
      "9   Added docs, fixed some bugs I introduced last ...        flaskext.py   \n",
      "12  Added docs, fixed some bugs I introduced last ...           flask.py   \n",
      "\n",
      "                                 Source Code (before)  \\\n",
      "3                                                 NaN   \n",
      "4                                                 NaN   \n",
      "8   # -*- coding: utf-8 -*-\\n#\\n# Flask documentat...   \n",
      "9                                                 NaN   \n",
      "12  # -*- coding: utf-8 -*-\\n\"\"\"\\n    flask\\n    ~...   \n",
      "\n",
      "                                Source Code (current)  \\\n",
      "3   <h3>About Flask</h3>\\n<p>\\n  Flask is a micro ...   \n",
      "4   <p class=\"logo\"><a href=\"{{ pathto(master_doc)...   \n",
      "8   # -*- coding: utf-8 -*-\\n#\\n# Flask documentat...   \n",
      "9   # flasky extensions.  flasky pygments style ba...   \n",
      "12  # -*- coding: utf-8 -*-\\n\"\"\"\\n    flask\\n    ~...   \n",
      "\n",
      "                                                 Diff  \\\n",
      "3   @@ -0,0 +1,7 @@\\n+<h3>About Flask</h3>\\n+<p>\\n...   \n",
      "4   @@ -0,0 +1,3 @@\\n+<p class=\"logo\"><a href=\"{{ ...   \n",
      "8   @@ -16,7 +16,7 @@ import sys, os\\n # If extens...   \n",
      "9   @@ -0,0 +1,96 @@\\n+# flasky extensions.  flask...   \n",
      "12  @@ -288,7 +288,7 @@ class Flask(object):\\n    ...   \n",
      "\n",
      "            LLM Inference (fix type)                 Rectified Message  \\\n",
      "3   add a link to the \"missing\" link  add a link to the \"missing\" link   \n",
      "4                update missing logo               update missing logo   \n",
      "8          add docs for docs/docs.py         add docs for docs/docs.py   \n",
      "9                    update style.py                   update style.py   \n",
      "12                   update flask.py                   update flask.py   \n",
      "\n",
      "     MI_Before  CC_Before  ...  LOC_After  Parsed_After  MI_Change  CC_Change  \\\n",
      "3    10.000000  83.000000  ...       90.0             0       16.0       58.0   \n",
      "4    38.000000  97.000000  ...        2.0             0       18.0        6.0   \n",
      "8   100.000000  43.000000  ...      245.0             1        0.0       42.0   \n",
      "9     8.000000  25.000000  ...       96.0             1       92.0       24.0   \n",
      "12   48.457562   1.647059  ...      523.0             1        0.0        0.0   \n",
      "\n",
      "    LOC_Change  Semantic_Similarity  Token_Similarity  Semantic_Class  \\\n",
      "3         66.0             0.212685          0.038637           Major   \n",
      "4         93.0             0.499913          0.322048           Major   \n",
      "8          4.0             0.999979          0.973101           Minor   \n",
      "9         49.0             0.112066          0.798650           Major   \n",
      "12         0.0             1.000000          0.994843           Minor   \n",
      "\n",
      "    Token_Class  Classes_Agree  \n",
      "3         Major            YES  \n",
      "4         Major            YES  \n",
      "8         Minor            YES  \n",
      "9         Minor             NO  \n",
      "12        Minor            YES  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"diff_analysis_with_final_classification.csv\")\n",
    "\n",
    "# Programming file extensions\n",
    "programming_extensions = [\n",
    "    \"py\", \"java\", \"cpp\", \"c\", \"cs\", \"js\", \"ts\", \"rb\", \"go\", \"php\", \"swift\", \"kt\", \"rs\", \"scala\", \"pl\", \"sh\", \"html\", \"css\"\n",
    "]\n",
    "\n",
    "# Filter rows with programming extensions\n",
    "df = df[df[\"Filename\"].apply(lambda x: x.split(\".\")[-1] if isinstance(x, str) and \".\" in x else \"\").isin(programming_extensions)]\n",
    "\n",
    "\n",
    "df.to_csv(\"diff_analysis_with_final_classification_filtered.csv\", index=False)\n",
    "\n",
    "\n",
    "print(\" Non-programming files removed. Saved to diff_analysis_with_final_classification_filtered.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319f3355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means of numeric columns:\n",
      "MI_Before               47.914244\n",
      "CC_Before               15.090951\n",
      "LOC_Before             529.089983\n",
      "Parsed_Before            0.778748\n",
      "MI_After                48.927197\n",
      "CC_After                13.899332\n",
      "LOC_After              534.099434\n",
      "Parsed_After             0.816594\n",
      "MI_Change               11.456005\n",
      "CC_Change                9.237366\n",
      "LOC_Change              20.971849\n",
      "Semantic_Similarity      0.936572\n",
      "Token_Similarity         0.902855\n",
      "dtype: float64\n",
      "\n",
      "Counts in Classes_Agree column:\n",
      "Classes_Agree\n",
      "YES    633\n",
      "NO      54\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df_filtered = pd.read_csv(\"diff_analysis_with_final_classification_filtered.csv\")\n",
    "\n",
    "\n",
    "means = df_filtered.mean(numeric_only=True)\n",
    "\n",
    "\n",
    "class_agree_counts = df_filtered[\"Classes_Agree\"].value_counts()\n",
    "\n",
    "\n",
    "print(\"Means of numeric columns:\")\n",
    "print(means)\n",
    "print(\"\\nCounts in Classes_Agree column:\")\n",
    "print(class_agree_counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DL Homework)",
   "language": "python",
   "name": "dl-homework-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
